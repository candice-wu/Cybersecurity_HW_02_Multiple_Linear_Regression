{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 網路安全威脅財務損失預測專案\n",
    "\n",
    "這是一個基於機器學習的專案，旨在預測網路安全事件可能造成的財務損失。專案採用 CRISP-DM（Cross-Industry Standard Process for Data Mining）流程方法論，從商業理解到模型部署，提供了一個完整的資料科學專案範例。\n",
    "\n",
    "使用者可以透過一個互動式的 Streamlit 網頁應用程式，輸入假設的攻擊情境，來預測潛在的財務損失，並深入探索資料與模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 商業理解 (Business Understanding)\n",
    "\n",
    "**目標：**\n",
    "隨著全球數位化轉型，網路安全事件頻傳，對企業造成的財務衝擊也日益嚴重。本專案的主要商業目標是建立一個數據驅動的預測模型，以協助企業或組織評估不同網路安全威脅事件可能帶來的財務損失（以百萬美元計）。\n",
    "\n",
    "透過這個模型，決策者可以：\n",
    "- 更精準地評估資安風險。\n",
    "- 優先處理和分配資源給可能造成重大損失的威脅類型。\n",
    "- 為資安保險、預算規劃和投資決策提供量化依據。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 資料理解 (Data Understanding)\n",
    "\n",
    "**資料來源：**\n",
    "本專案使用 `Global_Cybersecurity_Threats_2015-2024.csv` 資料集。此資料集包含了從 2015 年到 2024 年間的全球網路安全威脅事件記錄。\n",
    "\n",
    "**資料特徵：**\n",
    "資料集包含多種數值和類別特徵，例如：\n",
    "- **Attack Type**: 攻擊類型 (e.g., DDoS, Malware, Phishing)。\n",
    "- **Country**: 攻擊發生的國家。\n",
    "- **Sector**: 受攻擊的產業別。\n",
    "- **Number of Affected Users**: 受影響的使用者數量。\n",
    "- **Incident Resolution Time (in Hours)**: 事件解決所需時間（小時）。\n",
    "- **Financial Loss (in Million $)**: 財務損失（百萬美元），此為我們的**目標變數**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 載入資料集\n",
    "df = pd.read_csv(\"Global_Cybersecurity_Threats_2015-2024.csv\")\n",
    "print(\"資料集前五筆：\")\n",
    "display(df.head())"
   ]
  },
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"資料集資訊：\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"數值特徵統計摘要：\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 資料準備 (Data Preparation)\n",
    "\n",
    "此階段由 `prepare_data.py` 腳本負責，主要執行以下步驟：\n",
    "\n",
    "1.  **載入資料**：從 CSV 檔案載入資料集。\n",
    "2.  **特徵工程**：\n",
    "    *   **獨熱編碼 (One-Hot Encoding)**：將所有類別特徵（如 `Attack Type`, `Country`）轉換為數值格式，以便機器學習模型能夠處理。\n",
    "3.  **資料標準化**：\n",
    "    *   使用 `StandardScaler` 對所有數值特徵進行標準化，使其具有零均值和單位變異數。這一步驟對於線性模型和 RFE 的穩定性至關重要。\n",
    "4.  **資料分割**：\n",
    "    *   將處理後的資料集以 80/20 的比例分割為訓練集和測試集。此過程中使用固定的 `random_state` 以確保結果的可重現性。\n",
    "5.  **儲存產物**：將處理好的訓練集/測試集（`.npy` 格式）、`StandardScaler` 物件、以及特徵名稱列表儲存為檔案，供後續模型訓練和應用程式使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "df = pd.read_csv('Global_Cybersecurity_Threats_2015-2024.csv')\n",
    "\n",
    "# 設定 target 與 features\n",
    "target = \"Financial Loss (in Million $)\"\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# 類別欄位轉換\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# 數值標準化\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 訓練/測試集切分\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Save the data and scaler\n",
    "np.save('X_train.npy', X_train)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('y_test.npy', y_test)\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "joblib.dump(X.columns, 'feature_names.pkl')\n",
    "\n",
    "# Save full processed X and y for statsmodels\n",
    "np.save('X_full_processed.npy', X)\n",
    "np.save('y_full_processed.npy', y)\n",
    "print('\n✅ 資料準備完成，相關檔案已儲存。')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型建立 (Modeling)\n",
    "\n",
    "此階段由 `train_model.py` 腳本負責。我們建立了兩個互補的迴歸模型：\n",
    "\n",
    "1.  **Scikit-learn 線性迴歸 + RFE**:\n",
    "    *   **遞歸特徵消除 (RFE)**：首先，我們使用 RFE 來自動篩選出對預測財務損失最重要的 10 個特徵。\n",
    "    *   **線性迴歸 (Linear Regression)**：接著，我們使用一個標準的線性迴歸模型，僅在 RFE 篩選出的特徵上進行訓練。這個模型 (`cyber_risk_model.pkl`) 主要用於產生最終的預測值。\n",
    "\n",
    "2.  **Statsmodels OLS 模型**:\n",
    "    *   我們另外使用 `statsmodels` 函式庫建立了一個普通最小二乘法 (OLS) 模型。此模型 (`statsmodels_model.pkl`) 的優勢在於提供詳細的統計摘要，包括特徵的 p-value、信賴區間等。\n",
    "    *   在本專案中，它主要用於計算預測值的 **95% 預測區間**，並在「特徵重要性」分析中提供係數參考。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "import joblib\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data for sklearn model\n",
    "X_train = np.load('X_train.npy', allow_pickle=True)\n",
    "y_train = np.load('y_train.npy', allow_pickle=True)\n",
    "\n",
    "# Create a Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Use Recursive Feature Elimination (RFE) to select the best features\n",
    "rfe = RFE(model, n_features_to_select=10)\n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "\n",
    "# Train the sklearn model on the selected features\n",
    "model.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Save the trained sklearn model and the RFE selector\n",
    "joblib.dump(model, 'cyber_risk_model.pkl')\n",
    "joblib.dump(rfe, 'rfe.joblib')\n",
    "\n",
    "print(\"Sklearn model trained and saved successfully.\")\n",
    "\n",
    "# --- Fit and Save Statsmodels OLS Model ---\n",
    "\n",
    "# Load full processed X and y for statsmodels\n",
    "X_full_processed = np.load('X_full_processed.npy', allow_pickle=True)\n",
    "y_full_processed = np.load('y_full_processed.npy', allow_pickle=True)\n",
    "feature_names = joblib.load('feature_names.pkl')\n",
    "\n",
    "# Create DataFrame for statsmodels and ensure numeric types\n",
    "X_sm = pd.DataFrame(X_full_processed, columns=feature_names).astype(float)\n",
    "y_sm = pd.Series(y_full_processed).astype(float)\n",
    "\n",
    "# Add a constant to the X for statsmodels (for intercept)\n",
    "X_sm = sm.add_constant(X_sm)\n",
    "\n",
    "# Get the names of the features selected by RFE\n",
    "selected_feature_names_rfe = feature_names[rfe.support_].tolist()\n",
    "if 'const' not in selected_feature_names_rfe:\n",
    "    selected_feature_names_rfe.insert(0, 'const')\n",
    "\n",
    "# Filter X_sm to include only the RFE-selected features\n",
    "X_sm_selected = X_sm[selected_feature_names_rfe]\n",
    "\n",
    "# Fit statsmodels OLS model\n",
    "sm_model = sm.OLS(y_sm, X_sm_selected).fit()\n",
    "\n",
    "# Save the statsmodels model\n",
    "joblib.dump(sm_model, 'statsmodels_model.pkl')\n",
    "\n",
    "print(\"Statsmodels OLS model trained and saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型評估 (Evaluation)\n",
    "\n",
    "模型的評估在 Streamlit 應用程式的「分析頁面」中進行，主要包含以下幾個部分：\n",
    "\n",
    "- **迴歸指標**：在「模型性能」區塊，我們計算並展示了三個關鍵的迴歸評估指標：\n",
    "  - **R-squared (R²)**: 解釋了模型對目標變數變異性的解釋程度。\n",
    "  - **Root Mean Squared Error (RMSE)**: 衡量預測值與實際值之間的平均誤差幅度。\n",
    "  - **Mean Absolute Error (MAE)**: 提供了另一種誤差的衡量方式，較不受異常值影響。\n",
    "\n",
    "- **視覺化評估**：\n",
    "  - **實際 vs. 預測圖**：一個散點圖，用於比較實際損失與模型預測損失的一致性。\n",
    "  - **殘差圖**：用於檢查誤差是否隨機分佈，是評估模型假設的重要工具。\n",
    "  - **混淆矩陣**：雖然這是迴歸問題，但我們將連續的損失值分為「高、中、低」三個等級，並建立了一個互動式的混淆矩陣。這讓使用者可以從「分類」的角度評估模型在不同損失等級上的預測準確度，並可依特定特徵進行篩選分析。"
   ]
  },
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Load test data\n",
    "X_test = np.load('X_test.npy', allow_pickle=True)\n",
    "y_test = np.load('y_test.npy', allow_pickle=True)\n",
    "\n",
    "# Load model and rfe\n",
    "model = joblib.load('cyber_risk_model.pkl')\n",
    "rfe = joblib.load('rfe.joblib')\n",
    "\n",
    "# Transform test data\n",
    "selected_X_test = rfe.transform(X_test)\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = model.predict(selected_X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"### 模型評估指標 ###\")\n",
    "print(f\"- **R-squared (R²):** {r2:.3f}\")\n",
    "print(f\"- **Root Mean Squared Error (RMSE):** {rmse:.3f}\")\n",
    "print(f\"- **Mean Absolute Error (MAE):** {mae:.3f}\")\n",
    "\n",
    "# Scatter plot of actual vs. predicted\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=y_test, y=y_pred)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel(\"Actual Financial Loss (Million $)\")\n",
    "plt.ylabel(\"Predicted Financial Loss (Million $)\")\n",
    "plt.title(\"Actual vs. Predicted Financial Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 部署 (Deployment)\n",
    "\n",
    "本專案的最終產出是一個部署在 Streamlit 上的互動式網頁應用程式 (`5114050013_hw2.py`)。\n",
    "\n",
    "**應用程式功能：**\n",
    "\n",
    "- **預測頁面**：使用者可以在側邊欄輸入各種攻擊事件的參數（如年份、攻擊類型、影響用戶數等），點擊按鈕後，應用程式會立即回傳預測的財務損失金額，並以圖表形式展示其 95% 的預測區間。\n",
    "\n",
    "- **分析頁面**：提供了一個功能豐富的儀表板，讓使用者可以：\n",
    "  - 概覽資料集的統計特性與分佈。\n",
    "  - 探索不同特徵之間的關係以及它們對財務損失的影響。\n",
    "  - 查看模型的詳細性能指標與評估圖表。\n",
    "  - 分析 RFE 所選出的重要特徵。\n",
    "  - 透過互動式混淆矩陣，深入了解模型在特定情境下的分類表現。"
   ]
  },
    {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如何部署到 Streamlit Cloud\n",
    "1. Push 專案資料夾 to remote GitHub\n",
    "2. 至 https://share.streamlit.io，點擊 “Create app”\n",
    "3. Repository：下拉選擇 candice-wu/Cybersecurity_HW_02_Multiple_Linear_Regression\n",
    "4. Branch：Main\n",
    "5. Main file path：下拉選擇 5114050013_hw2.py\n",
    "6. App URL (optional)：可以改掉預設值，自行命名\n",
    "\n",
    "## 如何執行專案\n",
    "\n",
    "1.  **安裝依賴函式庫**:\n",
    "    ```bash\n",
    "    pip install -r requirements.txt\n",
    "    ```\n",
    "\n",
    "2.  **準備資料**:\n",
    "    執行資料準備腳本，此步驟會產生模型訓練所需的 `.npy` 和 `.pkl` 檔案。\n",
    "    ```bash\n",
    "    python prepare_data.py\n",
    "    ```\n",
    "\n",
    "3.  **訓練模型**:\n",
    "    執行模型訓練腳本，此步驟會產生訓練好的模型檔案。\n",
    "    ```bash\n",
    "    python train_model.py\n",
    "    ```\n",
    "\n",
    "4.  **啟動應用程式**:\n",
    "    執行 Streamlit 應用程式。\n",
    "    ```bash\n",
    "    streamlit run 5114050013_hw2.py\n",
    "    ```\n",
    "    接著在瀏覽器中開啟顯示的 URL (例如 `https://hw02-multiple-linear-regression.streamlit.app`) 即可開始使用。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
