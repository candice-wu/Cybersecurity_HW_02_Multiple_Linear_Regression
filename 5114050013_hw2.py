import streamlit as st

st.set_page_config(layout="wide", page_title="ç¶²è·¯å®‰å…¨å¨è„…è²¡å‹™æå¤±é æ¸¬", page_icon="ğŸ’»")

import numpy as np
import joblib
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
from sklearn.linear_model import LinearRegression # For interactive demo
from matplotlib.patches import Patch
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
from scipy.stats import norm

# Set Matplotlib font to avoid Chinese display issues (äº‚ç¢¼)
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS'] # Or any other font that supports Chinese characters
plt.rcParams['axes.unicode_minus'] = False

# Load model and related objects
model = joblib.load('cyber_risk_model.pkl') # Sklearn model
rfe = joblib.load('rfe.joblib')
scaler = joblib.load('scaler.pkl')
full_feature_names = joblib.load('feature_names.pkl')
sm_model = joblib.load('statsmodels_model.pkl') # Statsmodels model

# Dynamically extract original numerical and categorical columns and their possible options from full_feature_names
original_numerical_cols = [
    'Year', 
    'Number of Affected Users', 
    'Incident Resolution Time (in Hours)'
]
original_categorical_columns_map = {}

for feature in full_feature_names:
    if feature not in original_numerical_cols:
        # Example: 'Attack Type_DDoS' -> category='Attack Type', option='DDoS'
        parts = feature.split('_', 1)
        if len(parts) > 1:
            category = parts[0]
            option = parts[1]
            if category not in original_categorical_columns_map:
                original_categorical_columns_map[category] = []
            original_categorical_columns_map[category].append(option)

# Streamlit Page Navigation
page = st.sidebar.radio("é¸æ“‡é é¢", ["é æ¸¬é é¢", "åˆ†æé é¢"])

if page == "é æ¸¬é é¢":
    st.title("ğŸ’» ç¶²è·¯å®‰å…¨å¨è„…è²¡å‹™æå¤±é æ¸¬")
    st.markdown("é æ¸¬ä¸åŒç¶²è·¯å®‰å…¨æ”»æ“Šæ‰€é€ æˆçš„è²¡å‹™æå¤±ï¼ˆç™¾è¬ç¾å…ƒï¼‰ã€‚")

    # 2ï¸âƒ£ User Input (in sidebar)
    st.sidebar.header("è«‹è¼¸å…¥æ”»æ“Šäº‹ä»¶è³‡è¨Šï¼š")

    user_inputs_sidebar = {}

    # Numerical Features
    user_inputs_sidebar['Year'] = st.sidebar.slider("å¹´ä»½", 2015, 2024, 2023)
    user_inputs_sidebar['Number of Affected Users'] = st.sidebar.number_input("å½±éŸ¿ç”¨æˆ¶æ•¸", min_value=100, max_value=10_000_000, value=1000)
    user_inputs_sidebar['Incident Resolution Time (in Hours)'] = st.sidebar.slider("äº‹ä»¶è§£æ±ºæ™‚é–“ï¼ˆå°æ™‚ï¼‰", 1, 240, 48)

    # Categorical Features
    for category, options in original_categorical_columns_map.items():
        # Sort options for consistent display
        user_inputs_sidebar[category] = st.sidebar.selectbox(f"é¸æ“‡ {category}", sorted(options))

    # Prediction Button
    if st.sidebar.button("é æ¸¬è²¡å‹™æå¤±"):
        # 3ï¸âƒ£ Feature Transformation
        # Create a dictionary with all feature names initialized to 0
        input_data = {feature: 0 for feature in full_feature_names}

        # Populate numerical features based on user input
        for col in original_numerical_cols:
            input_data[col] = user_inputs_sidebar[col]

        # Populate one-hot encoded categorical features based on user input
        for category, selected_option in user_inputs_sidebar.items():
            if category not in original_numerical_cols: # Ensure only categorical features are processed
                one_hot_col_name = f'{category}_{selected_option}'
                if one_hot_col_name in full_feature_names: # Check if the generated feature name exists
                    input_data[one_hot_col_name] = 1

        # Convert to DataFrame, ensuring column order matches training
        input_df = pd.DataFrame([input_data], columns=full_feature_names)

        # --- Sklearn Model Prediction (for the main value) ---
        input_df_scaled = scaler.transform(input_df)
        selected_features_transformed = rfe.transform(input_df_scaled)
        prediction = model.predict(selected_features_transformed)[0]

        # --- Statsmodels for Prediction Interval ---
        # Create DataFrame for statsmodels prediction
        input_df_sm = pd.DataFrame([input_data], columns=full_feature_names)
        input_df_sm = sm.add_constant(input_df_sm, has_constant='add')
        
        # Ensure input_df_sm has only the features used by the statsmodels model
        # This requires getting the feature names from the fitted sm_model
        sm_model_features = sm_model.params.index.tolist()
        input_df_sm_selected = input_df_sm[sm_model_features]

        # Get prediction summary from statsmodels
        predictions_sm = sm_model.get_prediction(input_df_sm_selected).summary_frame(alpha=0.05)
        mean_pred = predictions_sm['mean'][0]
        lower_bound = predictions_sm['obs_ci_lower'][0] # Observation confidence interval (prediction interval)
        upper_bound = predictions_sm['obs_ci_upper'][0]

        st.subheader("ğŸ“Š é æ¸¬çµæœï¼š")
        st.metric("é æ¸¬æå¤±ï¼ˆç™¾è¬ç¾å…ƒï¼‰", f"{mean_pred:.2f}")

        # 5ï¸âƒ£ Visualization with Prediction Interval
        st.markdown("### ğŸ“ˆ é æ¸¬èˆ‡ 95% é æ¸¬å€é–“")
        st.info("é æ¸¬å€é–“é¡¯ç¤ºäº†åœ¨çµ¦å®šæ¨¡å‹ä¸ç¢ºå®šæ€§çš„æƒ…æ³ä¸‹ï¼Œæ–°è§€æ¸¬å€¼å¯èƒ½è½å…¥çš„ç¯„åœã€‚")

        fig, ax = plt.subplots(figsize=(8, 5))
        ax.bar(["Predicted Loss"], [mean_pred], color='skyblue', yerr=[[mean_pred - lower_bound], [upper_bound - mean_pred]], capsize=7)
        ax.set_ylabel("Financial Loss (Million $)")
        ax.set_title("Predicted Financial Loss with 95% Prediction Interval")
        st.pyplot(fig)

elif page == "åˆ†æé é¢":
    st.title("ğŸ” è³‡æ–™åˆ†æèˆ‡è¦–è¦ºåŒ–")
    st.markdown("æ¢ç´¢ç¶²è·¯å®‰å…¨å¨è„…è³‡æ–™ä¸­çš„é—œéµåˆ†ä½ˆã€é—œä¿‚å’Œç›¸é—œæ€§ã€‚")

    # Load original data
    df_analysis = pd.read_csv('Global_Cybersecurity_Threats_2015-2024.csv')

    tab1, tab2, tab3, tab4, tab5 = st.tabs(["è³‡æ–™æ¦‚è¦½", "ç‰¹å¾µåˆ†æ", "è¶¨å‹¢èˆ‡è¡æ“Š", "æ¨¡å‹è©•ä¼°", "äº’å‹•å¼å±•ç¤º"])

    with tab1:
        st.subheader("ğŸ“Š è³‡æ–™æ¦‚è¦½")
        st.write("### è³‡æ–™é›†é è¦½")
        st.dataframe(df_analysis.head())
        st.write(f"### è³‡æ–™é›†ç¶­åº¦: {df_analysis.shape[0]} è¡Œ, {df_analysis.shape[1]} åˆ—")
        st.write("### è³‡æ–™é›†æè¿°")
        st.dataframe(df_analysis.describe())

        st.subheader("ğŸ¯ è²¡å‹™æå¤± (ç›®æ¨™è®Šæ•¸) åˆ†ä½ˆ")
        financial_loss = df_analysis['Financial Loss (in Million $)']
        
        # Calculate Skewness
        skewness = financial_loss.skew()
        st.write(f"**ååº¦ (Skewness):** {skewness:.2f}")
        if skewness > 0.5:
            st.write("åˆ†ä½ˆå‘ˆå³åï¼ˆæ­£åï¼‰ï¼Œè¡¨ç¤ºæœ‰å°‘æ•¸æ¥µå¤§çš„æå¤±å€¼ã€‚")
        elif skewness < -0.5:
            st.write("åˆ†ä½ˆå‘ˆå·¦åï¼ˆè² åï¼‰ã€‚")
        else:
            st.write("åˆ†ä½ˆå¤§è‡´å°ç¨±ã€‚")

        # Plot distribution
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.histplot(financial_loss, kde=False, ax=ax, stat="density", label="Actual Distribution")
        
        # Overlay normal distribution
        xmin, xmax = ax.get_xlim()
        x = np.linspace(xmin, xmax, 100)
        p = norm.pdf(x, financial_loss.mean(), financial_loss.std())
        ax.plot(x, p, 'k', linewidth=2, label="Normal Distribution")
        
        ax.set_title('Distribution of Financial Loss vs. Normal Distribution')
        ax.set_xlabel('Financial Loss (in Million $)')
        ax.set_ylabel('Density')
        ax.legend()
        st.pyplot(fig)

    with tab2:
        st.subheader("ğŸ“ˆ ç‰¹å¾µåˆ†ä½ˆåˆ†æ")
        analysis_plot_type = st.selectbox(
            "é¸æ“‡åˆ†æé¡å‹",
            ["é—œéµè®Šæ•¸åˆ†ä½ˆ", 
             "é¡åˆ¥ç‰¹å¾µ vs. è²¡å‹™æå¤± (ç›’é¬šåœ–)", 
             "ç‰¹å¾µç›¸é—œæ€§ç†±åœ–",
             "ç‰¹å¾µ vs. ç›®æ¨™æ•£é»åœ–"]
        )

        if analysis_plot_type == "é—œéµè®Šæ•¸åˆ†ä½ˆ":
            st.write("### é—œéµè®Šæ•¸åˆ†ä½ˆ")
            # Numerical Feature Distributions
            for col in original_numerical_cols:
                st.write(f"#### Distribution of {col}")
                fig, ax = plt.subplots(figsize=(8, 4))
                sns.histplot(df_analysis[col], kde=True, ax=ax)
                ax.set_title(f'Distribution of {col}')
                ax.set_xlabel(col)
                ax.set_ylabel('Frequency')
                st.pyplot(fig)

            # Categorical Feature Distributions
            for col in original_categorical_columns_map.keys():
                st.write(f"#### Distribution of {col}")
                fig, ax = plt.subplots(figsize=(8, 4))
                sns.countplot(y=df_analysis[col], order=df_analysis[col].value_counts().index, ax=ax)
                ax.set_title(f'Distribution of {col}')
                ax.set_xlabel('Count')
                ax.set_ylabel(col)
                st.pyplot(fig)

        elif analysis_plot_type == "é¡åˆ¥ç‰¹å¾µ vs. è²¡å‹™æå¤± (ç›’é¬šåœ–)":
            st.write("### é¡åˆ¥ç‰¹å¾µ vs. è²¡å‹™æå¤± (ç›’é¬šåœ–)")
            for col in original_categorical_columns_map.keys():
                st.write(f"#### {col} vs. Financial Loss")
                fig, ax = plt.subplots(figsize=(10, 5))
                sns.boxplot(x=col, y='Financial Loss (in Million $)', data=df_analysis, ax=ax)
                plt.xticks(rotation=45, ha='right')
                ax.set_title(f'Financial Loss by {col}')
                ax.set_xlabel(col)
                ax.set_ylabel('Financial Loss (Million $)')
                st.pyplot(fig)

        elif analysis_plot_type == "ç‰¹å¾µç›¸é—œæ€§ç†±åœ–":
            st.write("### ç‰¹å¾µç›¸é—œæ€§ç†±åœ–")
            st.write("é¡¯ç¤ºè³‡æ–™é›†ä¸­æ•¸å€¼ç‰¹å¾µä¹‹é–“çš„ç›¸é—œæ€§ã€‚")
            fig, ax = plt.subplots(figsize=(10, 8))
            sns.heatmap(df_analysis[original_numerical_cols + ['Financial Loss (in Million $)']].corr(), annot=True, cmap="coolwarm", fmt=".2f", ax=ax)
            ax.set_title('Feature Correlation Heatmap')
            st.pyplot(fig)

        elif analysis_plot_type == "ç‰¹å¾µ vs. ç›®æ¨™æ•£é»åœ–":
            st.write("### ç‰¹å¾µ vs. ç›®æ¨™æ•£é»åœ–")
            all_features_for_scatter = original_numerical_cols + list(original_categorical_columns_map.keys())
            selected_feature_for_scatter = st.selectbox(
                "é¸æ“‡ä¸€å€‹ç‰¹å¾µä»¥å°ç…§è²¡å‹™æå¤±ç¹ªåœ–",
                all_features_for_scatter
            )
            if selected_feature_for_scatter:
                fig, ax = plt.subplots(figsize=(10, 6))
                sns.scatterplot(x=df_analysis[selected_feature_for_scatter], y=df_analysis['Financial Loss (in Million $)'], ax=ax)
                ax.set_title(f'{selected_feature_for_scatter} vs. Financial Loss')
                ax.set_xlabel(selected_feature_for_scatter)
                ax.set_ylabel('Financial Loss (Million $)')
                st.pyplot(fig)

    with tab3:
        st.subheader("ğŸš€ è¶¨å‹¢èˆ‡è¡æ“Šåˆ†æ")

        @st.cache_data
        def get_default_input(df_analysis):
            default_input_data = {}
            for col in original_numerical_cols:
                if col != 'Year':
                    default_input_data[col] = df_analysis[col].mean()
            for category in original_categorical_columns_map.keys():
                default_input_data[category] = df_analysis[category].mode()[0]
            return default_input_data

        def predict_loss(input_dict, alpha_value):
            input_df = pd.DataFrame([input_dict], columns=full_feature_names)
            
            # Prepare input for statsmodels prediction
            input_df_sm = pd.DataFrame([input_dict], columns=full_feature_names)
            input_df_sm = sm.add_constant(input_df_sm, has_constant='add')
            
            # Ensure input_df_sm has only the features used by the statsmodels model
            sm_model_features = sm_model.params.index.tolist()
            input_df_sm_selected = input_df_sm[sm_model_features]

            predictions = sm_model.get_prediction(input_df_sm_selected)
            summary_frame = predictions.summary_frame(alpha=alpha_value)
            predicted_mean = summary_frame['mean'][0]
            lower_bound = summary_frame['obs_ci_lower'][0]
            upper_bound = summary_frame['obs_ci_upper'][0]
            return predicted_mean, lower_bound, upper_bound

        def plot_impact_barchart(feature_name, default_input_data, ax, alpha_value):
            categories = sorted(df_analysis[feature_name].unique())
            predictions_data = []
            for cat_option in categories:
                base_input = {f: 0 for f in full_feature_names}
                base_input.update({k: v for k, v in default_input_data.items() if k in original_numerical_cols})
                base_input['Year'] = df_analysis['Year'].mode()[0]

                for cat, mode_val in default_input_data.items():
                    if cat in original_categorical_columns_map:
                        one_hot_col = f'{cat}_{mode_val}'
                        if one_hot_col in base_input:
                            base_input[one_hot_col] = 1

                for option in original_categorical_columns_map[feature_name]:
                    one_hot_col = f'{feature_name}_{option}'
                    if one_hot_col in base_input:
                        base_input[one_hot_col] = 0
                one_hot_col = f'{feature_name}_{cat_option}'
                if one_hot_col in base_input:
                    base_input[one_hot_col] = 1

                predicted_mean, lower_bound, upper_bound = predict_loss(base_input, alpha_value)
                predictions_data.append({
                    'Category': cat_option,
                    'Predicted Loss': predicted_mean,
                    'Lower Bound': lower_bound,
                    'Upper Bound': upper_bound
                })
            
            predictions_df = pd.DataFrame(predictions_data)

            # Temporarily set yerr to a scalar for debugging
            ax.bar(
                predictions_df['Category'].tolist(),
                predictions_df['Predicted Loss'].tolist(),
                yerr=0.1,
                capsize=5,
                color='skyblue' # Default color for consistency
            )
            ax.set_xlabel(feature_name)
            ax.set_ylabel("Predicted Financial Loss (Million $)")
            ax.set_title(f'Impact of {feature_name} on Financial Loss')
            ax.tick_params(axis='x', rotation=45)

        def on_pick(event, trend_df, feature_name, ax):
            # This function will be the callback for pick events.
            artist = event.artist
            xmouse, ymouse = event.mouseevent.xdata, event.mouseevent.ydata
            x, y = artist.get_xdata(), artist.get_ydata()
            ind = event.ind
            
            if not ind.any():
                return

            # Find the closest point
            w, h = ax.get_figure().get_size_inches() * ax.get_figure().get_dpi()
            ax_w = ax.get_position().width * w
            ax_h = ax.get_position().height * h
            
            # Transform data to display coordinates
            xy_data = ax.transData.transform(np.vstack([x,y]).T)
            x_screen, y_screen = xy_data[:, 0], xy_data[:, 1]
            
            # Mouse position in display coordinates
            mouse_x_screen, mouse_y_screen = ax.transData.transform([xmouse, ymouse])

            # Find the index of the closest point in screen coordinates
            distances = np.sqrt((x_screen[ind] - mouse_x_screen)**2 + (y_screen[ind] - mouse_y_screen)**2)
            closest_ind_in_ind = np.argmin(distances)
            closest_ind = ind[closest_ind_in_ind]

            # Get the data point
            picked_year = x[closest_ind]
            picked_loss = y[closest_ind]
            
            # Find the category from the trend_df
            category_value = trend_df[(trend_df['Year'] == picked_year) & (np.isclose(trend_df['Predicted Loss'], picked_loss))][feature_name].iloc[0]

            # Remove previous annotations
            for ann in ax.findobj(type=plt.Annotation):
                ann.remove()

            # Add new annotation
            ax.annotate(f'Year: {int(picked_year)}\nLoss: ${picked_loss:.2f}M\n{feature_name}: {category_value}',
                        xy=(picked_year, picked_loss),
                        xytext=(0, 20),
                        textcoords='offset points',
                        ha='center',
                        arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0.1'),
                        bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.7))
            
            # Redraw the figure
            fig = ax.get_figure()
            fig.canvas.draw_idle()

        def plot_predicted_trend_chart(feature_name, default_input_data, ax, alpha_value, confidence_level):
            trend_data = []
            years = range(2015, 2025)
            categories = sorted(df_analysis[feature_name].unique())

            for year in years:
                for cat_option in categories:
                    base_input = {feature: 0 for feature in full_feature_names}
                    for col, val in default_input_data.items():
                        if col in original_numerical_cols and col != 'Year':
                            base_input[col] = val
                    base_input['Year'] = year

                    for cat, mode_val in default_input_data.items():
                        if cat in original_categorical_columns_map:
                            one_hot_col = f'{cat}_{mode_val}'
                            if one_hot_col in base_input:
                                base_input[one_hot_col] = 1
                    
                    for option in original_categorical_columns_map[feature_name]:
                        one_hot_col = f'{feature_name}_{option}'
                        if one_hot_col in base_input:
                            base_input[one_hot_col] = 0
                    one_hot_col = f'{feature_name}_{cat_option}'
                    if one_hot_col in base_input:
                        base_input[one_hot_col] = 1

                    predicted_mean, lower_bound, upper_bound = predict_loss(base_input, alpha_value)
                    trend_data.append({
                        'Year': year, 
                        feature_name: cat_option, 
                        'Predicted Loss': predicted_mean,
                        'Lower Bound': lower_bound,
                        'Upper Bound': upper_bound
                    })
            
            trend_df = pd.DataFrame(trend_data)
            
            # Plotting with prediction intervals
            lines = []
            for category in categories:
                subset = trend_df[trend_df[feature_name] == category]
                # line, = ax.plot(subset['Year'], subset['Predicted Loss'], marker='o', linestyle='-', label=category, picker=5)
                # lines.append(line)
                # ax.fill_between(subset['Year'], subset['Lower Bound'], subset['Upper Bound'], facecolor=line.get_color(), alpha=0.2)
                sns.lineplot(data=subset, x='Year', y='Predicted Loss', ax=ax, marker='o', label=category)
                ax.fill_between(subset['Year'], subset['Lower Bound'], subset['Upper Bound'], color='orange', alpha=0.2)
            
            # Create a proxy artist for the prediction interval legend entry
            # prediction_interval_patch = Patch(color='orange', alpha=0.2, label='95% Prediction Interval')
            prediction_interval_patch = Patch(color='orange', alpha=0.2, label=f'{confidence_level}% Prediction Interval')
            
            # Get existing handles and labels
            handles, labels = ax.get_legend_handles_labels()
            
            # Add the prediction interval patch to handles and labels
            # handles.append(prediction_interval_patch)
            # labels.append('95% Prediction Interval')
            handles, labels = ax.get_legend_handles_labels()
            handles.append(prediction_interval_patch)
            labels.append(f'{confidence_level}% Prediction Interval')


            ax.set_title(f'Predicted Financial Loss Trend by {feature_name} with 95% Prediction Interval')
            ax.set_ylabel("Predicted Financial Loss (Million $)")
            # ä¿®æ­£åœ–ä¾‹ä½ç½®åœ¨å³ä¸Šè§’ï¼Œé¿å…é‡ç–Š
            ax.legend(handles=handles, labels=labels, title=feature_name, loc='upper right')

            fig = ax.get_figure()
            fig.canvas.mpl_connect('pick_event', lambda event: on_pick(event, trend_df, feature_name, ax))

        def plot_actual_trend_chart(feature_name, df, ax):
            actual_trend_df = df.groupby(['Year', feature_name])['Financial Loss (in Million $)'].mean().reset_index()
            sns.lineplot(data=actual_trend_df, x='Year', y='Financial Loss (in Million $)', hue=feature_name, ax=ax, marker='o')
            ax.set_title(f'Actual Average Financial Loss Trend by {feature_name}')
            ax.set_ylabel("Actual Avg. Financial Loss (Million $)")
            ax.legend(title=feature_name)

        st.write("### ğŸ† Top 3 å¨è„…è²¡å‹™æå¤±å½±éŸ¿å› å­")
        sm_model_coefs = sm_model.params.drop('const', errors='ignore')
        feature_importance_df = pd.DataFrame({
            'Feature': sm_model_coefs.index,
            'Coefficient': sm_model_coefs.values
        })
        feature_importance_df['Absolute_Coefficient'] = feature_importance_df['Coefficient'].abs()
        
        categorical_importances = {}
        for cat_name in original_categorical_columns_map.keys():
            cat_features = [f for f in feature_importance_df['Feature'] if f.startswith(cat_name + '_')]
            if cat_features:
                mean_abs_coef = feature_importance_df[feature_importance_df['Feature'].isin(cat_features)]['Absolute_Coefficient'].mean()
                categorical_importances[cat_name] = mean_abs_coef

        top_3_cat_features = pd.Series(categorical_importances).nlargest(3).index.tolist()

        st.write("æ ¹æ“šæ¨¡å‹ä¿‚æ•¸ï¼Œå°è²¡å‹™æå¤±å½±éŸ¿æœ€å¤§çš„å‰ä¸‰å¤§é¡åˆ¥ç‰¹å¾µæ˜¯ï¼š")
        for i, feature in enumerate(top_3_cat_features):
            st.markdown(f"{i+1}. **{feature}**")

        default_input = get_default_input(df_analysis)

        for feature in top_3_cat_features:
            st.write(f"#### åˆ†æï¼š{feature}")
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))
            plot_impact_barchart(feature, default_input, ax=ax1, alpha_value=0.05)
            plot_actual_trend_chart(feature, df_analysis, ax=ax2)
            st.pyplot(fig)

        st.write("### ğŸ“ˆ äº’å‹•å¼é æ¸¬è¶¨å‹¢åˆ†æ")
        
        # Add a slider for confidence level
        confidence_level = st.slider(
            "é¸æ“‡é æ¸¬å€é–“çš„ä¿¡è³´æ°´æº– (%)",
            min_value=80,
            max_value=99,
            value=95,
            step=1,
            help="èª¿æ•´æ­¤å€¼ä»¥æ”¹è®Šé æ¸¬å€é–“çš„å¯¬åº¦ã€‚ä¾‹å¦‚ï¼Œ95% è¡¨ç¤ºæœ‰ 95% çš„æ©Ÿç‡çœŸå¯¦å€¼æœƒè½åœ¨æ­¤å€é–“å…§ã€‚"
        )
        alpha_value = 1 - (confidence_level / 100) # Convert percentage to alpha for statsmodels

        trend_type = st.selectbox("é¸æ“‡è¶¨å‹¢åœ–é¡å‹", ["å¯¦éš›è¶¨å‹¢ (Actual Trend)", "é æ¸¬è¶¨å‹¢ (Predicted Trend)"])
        
        selected_feature_for_trend = st.selectbox(
            "é¸æ“‡ä¸€å€‹ç‰¹å¾µä¾†åˆ†æå…¶è¶¨å‹¢",
            list(original_categorical_columns_map.keys())
        )

        if trend_type == "å¯¦éš›è¶¨å‹¢ (Actual Trend)":
            if selected_feature_for_trend:
                fig, ax = plt.subplots(figsize=(12, 7))
                plot_actual_trend_chart(selected_feature_for_trend, df_analysis, ax)
                st.pyplot(fig)
        elif trend_type == "é æ¸¬è¶¨å‹¢ (Predicted Trend)":
            st.info("æ­¤åœ–è¡¨é¡¯ç¤ºæ¨¡å‹çš„ã€é æ¸¬ã€è¶¨å‹¢ã€‚ç·šæ¢å¹³è¡Œçš„åŸå› ï¼Œæ˜¯å› ç‚ºåœ¨æ§åˆ¶æ‰€æœ‰å…¶ä»–è®Šæ•¸ä¸è®Šçš„æƒ…æ³ä¸‹ï¼Œã€å¹´ä»½ã€çš„è®Šå‹•å°æ¯å€‹é¡åˆ¥çš„é æ¸¬å€¼ç”¢ç”Ÿäº†å›ºå®šçš„ç·šæ€§å½±éŸ¿ã€‚")
            if selected_feature_for_trend:
                fig, ax = plt.subplots(figsize=(12, 7))
                plot_predicted_trend_chart(selected_feature_for_trend, default_input, ax, alpha_value, confidence_level)
                st.pyplot(fig)

    with tab4:
        st.subheader("ğŸš€ æ¨¡å‹æ€§èƒ½")
        # Load test data
        X_test = np.load('X_test.npy', allow_pickle=True)
        y_test = np.load('y_test.npy', allow_pickle=True)

        # Preprocess X_test
        # X_test is already scaled from prepare_data.py
        selected_X_test = rfe.transform(X_test)

        # Generate predictions
        y_pred = model.predict(selected_X_test)

        from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

        r2 = r2_score(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        mae = mean_absolute_error(y_test, y_pred)

        st.write("### æ¨¡å‹è©•ä¼°æŒ‡æ¨™")
        st.write(f"- **R-squared (RÂ²):** {r2:.3f}")
        st.write(f"- **Root Mean Squared Error (RMSE):** {rmse:.3f}")
        st.write(f"- **Mean Absolute Error (MAE):** {mae:.3f}")

        st.write("#### å¯¦éš› vs. é æ¸¬æå¤±æ•£é»åœ–")
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.scatterplot(x=y_test, y=y_pred, ax=ax)
        ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
        ax.set_xlabel("Actual Financial Loss (Million $)")
        ax.set_ylabel("Predicted Financial Loss (Million $)")
        ax.set_title("Actual vs. Predicted Financial Loss")
        st.pyplot(fig)

        st.write("#### æ®˜å·®åœ–")
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.scatterplot(x=y_pred, y=(y_test - y_pred), ax=ax)
        ax.axhline(y=0, color='r', linestyle='--')
        ax.set_xlabel("Predicted Financial Loss (Million $)")
        ax.set_ylabel("Residuals (Actual - Predicted)")
        ax.set_title("Residuals Plot")
        st.pyplot(fig)

        st.subheader("ğŸ” RFE ç‰¹å¾µåˆ†æ (éæ­¸ç‰¹å¾µæ¶ˆé™¤)")
        st.write("RFE é€ééæ­¸åœ°è€ƒæ…®è¶Šä¾†è¶Šå°çš„ç‰¹å¾µé›†ä¾†é¸æ“‡ç‰¹å¾µã€‚")
        st.write(f"RFE æ¨¡å‹é¸æ“‡äº† {rfe.n_features_} å€‹ç‰¹å¾µã€‚")
        
        selected_rfe_features = full_feature_names[rfe.support_]
        st.write("#### RFE é¸æ“‡çš„ç‰¹å¾µ:")
        for feature in selected_rfe_features.tolist():
            st.markdown(f"- `{feature}`")

        st.subheader("ğŸŒŸ ç‰¹å¾µé‡è¦æ€§")
        st.write("å°æ–¼ç·šæ€§æ¨¡å‹ï¼Œç‰¹å¾µé‡è¦æ€§å¯ä»¥å¾ä¿‚æ•¸çš„çµ•å°å¤§å°æ¨æ–·å‡ºä¾†ã€‚")

        sm_model_coefs = sm_model.params.drop('const', errors='ignore')
        
        feature_importance_df = pd.DataFrame({
            'Feature': sm_model_coefs.index,
            'Coefficient': sm_model_coefs.values
        })
        feature_importance_df['Absolute_Coefficient'] = feature_importance_df['Coefficient'].abs()
        feature_importance_df = feature_importance_df.sort_values(by='Absolute_Coefficient', ascending=False)

        st.write("#### ç‰¹å¾µä¿‚æ•¸ (ä¾†è‡ª Statsmodels OLS æ¨¡å‹):")
        st.dataframe(feature_importance_df[['Feature', 'Coefficient']])

        fig, ax = plt.subplots(figsize=(10, 7))
        sns.barplot(x='Absolute_Coefficient', y='Feature', data=feature_importance_df.head(15), ax=ax, palette='viridis')
        ax.set_title('Top 15 Feature Importances (Absolute Coefficients)')
        ax.set_xlabel('Absolute Coefficient Value')
        ax.set_ylabel('Feature')
        st.pyplot(fig)

        st.subheader(" outliers ç•°å¸¸å€¼åˆ†æ")
        st.markdown("è­˜åˆ¥ä¸¦è¦–è¦ºåŒ–æ•¸å€¼ç‰¹å¾µå’Œè²¡å‹™æå¤±ä¸­çš„æ½›åœ¨ç•°å¸¸å€¼ã€‚")

        st.write("#### æ•¸å€¼ç‰¹å¾µçš„ç›’é¬šåœ– (ç•°å¸¸å€¼æª¢æ¸¬)")
        numerical_and_target_cols = original_numerical_cols + ['Financial Loss (in Million $)']
        selected_outlier_col = st.selectbox("ç‚ºç›’é¬šåœ–é¸æ“‡ä¸€å€‹æ•¸å€¼ç‰¹å¾µ", numerical_and_target_cols)
        
        if selected_outlier_col:
            fig, ax = plt.subplots(figsize=(8, 4))
            sns.boxplot(x=df_analysis[selected_outlier_col], ax=ax)
            ax.set_title(f'Box Plot of {selected_outlier_col}')
            ax.set_xlabel(selected_outlier_col)
            st.pyplot(fig)

        st.write("#### è²¡å‹™æå¤±ç•°å¸¸å€¼æª¢æ¸¬ (ä½¿ç”¨ IQR)")
        Q1 = df_analysis['Financial Loss (in Million $)'].quantile(0.25)
        Q3 = df_analysis['Financial Loss (in Million $)'].quantile(0.75)
        IQR = Q3 - Q1
        outlier_threshold_upper = Q3 + 1.5 * IQR
        outlier_threshold_lower = Q1 - 1.5 * IQR

        df_outliers = df_analysis[(df_analysis['Financial Loss (in Million $)'] > outlier_threshold_upper) |
                                  (df_analysis['Financial Loss (in Million $)'] < outlier_threshold_lower)]

        if not df_outliers.empty:
            st.write(f"ä½¿ç”¨ IQR æ–¹æ³•åœ¨è²¡å‹™æå¤±ä¸­ç™¼ç¾ {len(df_outliers)} å€‹æ½›åœ¨ç•°å¸¸å€¼ã€‚")
            st.dataframe(df_outliers[['Year', 'Financial Loss (in Million $)', 'Attack Type', 'Country']])
        else:
            st.write("ä½¿ç”¨ IQR æ–¹æ³•åœ¨è²¡å‹™æå¤±ä¸­æœªç™¼ç¾é¡¯è‘—ç•°å¸¸å€¼ã€‚")

        fig, ax = plt.subplots(figsize=(10, 6))
        sns.scatterplot(x=df_analysis['Year'], y=df_analysis['Financial Loss (in Million $)'], label='All Data', ax=ax)
        if not df_outliers.empty:
            sns.scatterplot(x=df_outliers['Year'], y=df_outliers['Financial Loss (in Million $)'], color='red', label='Outlier', ax=ax)
        ax.axhline(y=outlier_threshold_upper, color='orange', linestyle=':', label='Upper IQR Bound')
        ax.axhline(y=outlier_threshold_lower, color='orange', linestyle=':', label='Lower IQR Bound')
        ax.set_title('Financial Loss vs. Year with Outlier Bounds')
        ax.set_xlabel('Year')
        ax.set_ylabel('Financial Loss (Million $)')
        ax.legend()
        st.pyplot(fig)
        
        st.subheader("ğŸ“ˆ æ··æ·†çŸ©é™£")
        st.markdown("ç‚ºäº†ç”¢ç”Ÿæ··æ·†çŸ©é™£ï¼Œæˆ‘å€‘å°‡é€£çºŒçš„è²¡å‹™æå¤±ç›®æ¨™è®Šæ•¸è½‰æ›ç‚ºä¸‰å€‹é¡åˆ¥ï¼šä½ã€ä¸­ã€é«˜ã€‚æ‚¨å¯ä»¥ä¾ç‰¹å®šç‰¹å¾µç¯©é¸è³‡æ–™ï¼Œè§€å¯Ÿæ¨¡å‹åœ¨ä¸åŒæƒ…å¢ƒä¸‹çš„è¡¨ç¾ã€‚")

        # --- Data Loading and Preparation ---
        # Recreate the train-test split on the original data to get access to original features for filtering
        target = "Financial Loss (in Million $)"
        features = df_analysis.drop(columns=[target])
        y_full = df_analysis[target]
        # The split is identical to prepare_data.py due to random_state=42
        _, X_test_original_df, _, y_test = train_test_split(features, y_full, test_size=0.2, random_state=42)
        
        # Load the processed test set to make predictions
        X_test_processed = np.load('X_test.npy', allow_pickle=True)
        selected_X_test = rfe.transform(X_test_processed)
        y_pred = model.predict(selected_X_test)

        # --- Interactive Filtering ---
        categorical_cols = list(original_categorical_columns_map.keys())
        filter_feature = st.selectbox("é¸æ“‡ä¸€å€‹ç‰¹å¾µé€²è¡Œç¯©é¸", ["ç„¡"] + categorical_cols)

        y_test_filtered = y_test
        y_pred_filtered = y_pred

        if filter_feature != "ç„¡":
            unique_values = ["å…¨éƒ¨"] + sorted(X_test_original_df[filter_feature].unique().tolist())
            filter_value = st.selectbox(f"é¸æ“‡ '{filter_feature}' çš„å€¼", unique_values)

            if filter_value != "å…¨éƒ¨":
                # Get original indices of the full test set
                original_test_indices = y_test.index.tolist() 

                # Get original indices of the filtered subset
                indices_to_keep = X_test_original_df[X_test_original_df[filter_feature] == filter_value].index

                # Find the positions (0 to N-1) of the items to keep in the original test set
                positional_indices = [original_test_indices.index(i) for i in indices_to_keep if i in original_test_indices]

                # Filter y_pred and y_test
                y_pred_filtered = y_pred[positional_indices]
                y_test_filtered = y_test.iloc[positional_indices]


        if len(y_test_filtered) == 0:
            st.warning("æ²’æœ‰ç¬¦åˆç¯©é¸æ¢ä»¶çš„è³‡æ–™ã€‚")
        else:
            # --- Confusion Matrix Calculation and Display ---
            # Define bins and labels for categorization based on the filtered data
            try:
                bins = pd.qcut(y_test_filtered, q=3, retbins=True, duplicates='drop')[1]
                labels = ["ä½", "ä¸­", "é«˜"]
            except ValueError: # Happens if not enough unique values for 3 quantiles
                try:
                    bins = pd.qcut(y_test_filtered, q=2, retbins=True, duplicates='drop')[1]
                    labels = ["ä½", "é«˜"]
                except ValueError: # Happens if all values are the same
                    bins = [y_test_filtered.min(), y_test_filtered.max()]
                    labels = ["å–®ä¸€å€¼"]


            y_test_cat = pd.cut(y_test_filtered, bins=bins, labels=labels, include_lowest=True)
            y_pred_cat = pd.cut(y_pred_filtered, bins=bins, labels=labels, include_lowest=True)
            
            # Handle cases where predictions might fall out of y_test bins
            if y_pred_cat.isnull().any():
                y_pred_cat = y_pred_cat.cat.add_categories(['é æ¸¬è¶…å‡ºç¯„åœ'])
                y_pred_cat = y_pred_cat.fillna('é æ¸¬è¶…å‡ºç¯„åœ')
                all_labels = list(labels) + ['é æ¸¬è¶…å‡ºç¯„åœ']
            else:
                all_labels = labels

            st.write("#### æå¤±é¡åˆ¥å®šç¾©:")
            if len(bins) > 1 and "å–®ä¸€å€¼" not in labels:
                for i in range(len(bins) - 1):
                    st.write(f"- **{labels[i]}**: ${bins[i]:.2f}M - ${bins[i+1]:.2f}M")

            # Compute confusion matrix
            cm = confusion_matrix(y_test_cat, y_pred_cat, labels=all_labels)
            cm_df = pd.DataFrame(cm, index=all_labels, columns=all_labels)

            st.write("#### æ··æ·†çŸ©é™£:")
            st.write("æ­¤çŸ©é™£é¡¯ç¤ºäº†æ¨¡å‹åœ¨é æ¸¬ä¸åŒæå¤±ç­‰ç´šæ™‚çš„è¡¨ç¾ã€‚")
            
            fig, ax = plt.subplots(figsize=(8, 6))
            sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', ax=ax)
            ax.set_title('Confusion Matrix for Financial Loss Categories')
            ax.set_xlabel('Predicted Labels')
            ax.set_ylabel('True Labels')
            st.pyplot(fig)

    with tab5:
        st.subheader("ğŸ•¹ï¸ äº’å‹•å¼ç·šæ€§è¿´æ­¸å±•ç¤º")
        
        demo_type = st.radio("é¸æ“‡å±•ç¤ºæ¨¡å¼", ["çœŸå¯¦è³‡æ–™æ¢ç´¢ (Real Data Exploration)", "æ¨¡æ“¬è³‡æ–™æ•™å­¸ (Synthetic Data Demo)"])

        if demo_type == "æ¨¡æ“¬è³‡æ–™æ•™å­¸ (Synthetic Data Demo)":
            st.info("æ­¤ç‚ºæ•™å­¸ç”¨é€”çš„æ¨¡æ“¬è³‡æ–™ã€‚æ‚¨å¯ä»¥èª¿æ•´ä¸‹æ–¹åƒæ•¸ï¼Œè§€å¯Ÿç·šæ€§è¿´æ­¸å¦‚ä½•æ“¬åˆä¸åŒå‹æ…‹çš„è³‡æ–™ã€‚")
            # Input controls for the interactive demo
            a_true = st.slider("çœŸå¯¦æ–œç‡ (a)", min_value=-5.0, max_value=5.0, value=2.0, step=0.1)
            noise_std = st.slider("å™ªè²æ¨™æº–å·®", min_value=0.0, max_value=10.0, value=2.0, step=0.1)
            n_points = st.slider("æ•¸æ“šé»æ•¸é‡", min_value=10, max_value=500, value=100, step=10)

            # Generate synthetic data
            X_synth = np.random.rand(n_points) * 10
            y_true = a_true * X_synth
            noise = np.random.randn(n_points) * noise_std
            y_synth = y_true + noise

            # Perform simple linear regression
            synth_model = LinearRegression()
            synth_model.fit(X_synth.reshape(-1, 1), y_synth)
            y_pred_synth = synth_model.predict(X_synth.reshape(-1, 1))
            r2_synth = synth_model.score(X_synth.reshape(-1, 1), y_synth)

            # Plotting
            fig, ax = plt.subplots(figsize=(10, 6))
            sns.scatterplot(x=X_synth, y=y_synth, label="Raw Data", ax=ax)
            ax.plot(X_synth, y_true, color='green', linestyle='--', label="True Relationship")
            ax.plot(X_synth, y_pred_synth, color='red', label="Fitted Regression Line")
            ax.set_xlabel("X Value")
            ax.set_ylabel("Y Value")
            ax.set_title("Interactive Linear Regression")
            ax.legend()
            st.pyplot(fig)

            st.write(f"æ“¬åˆæ¨¡å‹çš„ R-squared: {r2_synth:.2f}")

        elif demo_type == "çœŸå¯¦è³‡æ–™æ¢ç´¢ (Real Data Exploration)":
            st.markdown("å¾çœŸå¯¦è³‡æ–™é›†ä¸­é¸æ“‡ä¸€å€‹æ•¸å€¼ç‰¹å¾µï¼Œè§€å¯Ÿå…¶èˆ‡è²¡å‹™æå¤±çš„ç·šæ€§é—œä¿‚ã€‚")
            
            feature_to_plot = st.selectbox("é¸æ“‡ä¸€å€‹æ•¸å€¼ç‰¹å¾µ", original_numerical_cols)
            
            if feature_to_plot:
                X_real = df_analysis[[feature_to_plot]]
                y_real = df_analysis['Financial Loss (in Million $)']

                # Simple linear regression
                real_model = LinearRegression()
                real_model.fit(X_real, y_real)
                y_pred_real = real_model.predict(X_real)
                r2_real = real_model.score(X_real, y_real)
                coef = real_model.coef_[0]
                intercept = real_model.intercept_

                # Plotting
                fig, ax = plt.subplots(figsize=(10, 6))
                sns.scatterplot(x=df_analysis[feature_to_plot], y=y_real, label="Actual Data", ax=ax)
                ax.plot(df_analysis[feature_to_plot], y_pred_real, color='red', label="Fitted Regression Line")
                ax.set_xlabel(feature_to_plot)
                ax.set_ylabel("Financial Loss (in Million $)")
                ax.set_title(f'Simple Linear Regression: {feature_to_plot} vs. Financial Loss')
                ax.legend()
                st.pyplot(fig)

                st.write(f"**R-squared:** {r2_real:.3f}")
                st.write(f"**è¿´æ­¸æ–¹ç¨‹å¼:** `Financial Loss = {coef:.2f} * ({feature_to_plot}) + {intercept:.2f}`")
                st.info("""
                **æ–¹ç¨‹å¼è§£è®€:**

                é€™å€‹è¿´æ­¸æ–¹ç¨‹å¼ä»£è¡¨äº†æ‚¨æ‰€é¸çš„å–®ä¸€ç‰¹å¾µï¼ˆXè»¸ï¼‰èˆ‡ã€Œè²¡å‹™æå¤±ã€ï¼ˆYè»¸ï¼‰ä¹‹é–“çš„æœ€ä½³æ“¬åˆç›´ç·šã€‚

                *   **`a` (æ–œç‡/ä¿‚æ•¸):** ä»£è¡¨æ‚¨é¸æ“‡çš„ç‰¹å¾µ**æ¯å¢åŠ ä¸€å€‹å–®ä½**ï¼Œã€Œè²¡å‹™æå¤±ã€é è¨ˆæœƒæ”¹è®Šå¤šå°‘ã€‚
                *   **`b` (æˆªè·):** ä»£è¡¨ç•¶æ‚¨é¸æ“‡çš„ç‰¹å¾µå€¼ç‚º 0 æ™‚ï¼Œæ¨¡å‹çš„é æ¸¬æå¤±æ˜¯å¤šå°‘ã€‚

                æ¯ç•¶æ‚¨é¸æ“‡ä¸€å€‹æ–°çš„ç‰¹å¾µï¼Œç¨‹å¼éƒ½æœƒé‡æ–°è¨ˆç®—ä¸€æ¬¡æœ€é©åˆæè¿°å®ƒå€‘å€†é—œä¿‚çš„ç›´ç·šï¼Œå› æ­¤æ–¹ç¨‹å¼æœƒéš¨ä¹‹æ”¹è®Šã€‚
                """)