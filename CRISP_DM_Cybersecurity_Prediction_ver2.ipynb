{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 網路安全威脅財務損失預測專案\n",
    "\n",
    "這是一個基於機器學習的專案，旨在預測網路安全事件可能造成的財務損失。專案採用 CRISP-DM（Cross-Industry Standard Process for Data Mining）流程方法論，從商業理解到模型部署，提供了一個完整的資料科學專案範例。\n",
    "\n",
    "使用者可以透過一個互動式的 Streamlit 網頁應用程式，輸入假設的攻擊情境，來預測潛在的財務損失，並深入探索資料與模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 商業理解 (Business Understanding)\n",
    "\n",
    "**目標：**\n",
    "隨著全球數位化轉型，網路安全事件頻傳，對企業造成的財務衝擊也日益嚴重。本專案的主要商業目標是建立一個數據驅動的預測模型，以協助企業或組織評估不同網路安全威脅事件可能帶來的財務損失（以百萬美元計）。\n",
    "\n",
    "透過這個模型，決策者可以：\n",
    "- 更精準地評估資安風險。\n",
    "- 優先處理和分配資源給可能造成重大損失的威脅類型。\n",
    "- 為資安保險、預算規劃和投資決策提供量化依據。"
   ]
  },
    {                                                                                                           
     "cell_type": "markdown",                                                                                   
     "metadata": {},                                                                                            
     "source": [
      "## 2. 資料理解 (Data Understanding)\n",
      "\n",
      "**資料來源：**\n",
      "本專案使用 `Global_Cybersecurity_Threats_2015-2024.csv` 資料集。此資料集包含了從 2015 年到 2024 年間的全球網路安全威脅事件記錄。\n",
      "\n",
      "**資料特徵：**\n",
      "資料集包含多種數值和類別特徵，例如：\n",
      "- **Attack Type**: 攻擊類型 (e.g., DDoS, Malware, Phishing)。\n",
      "- **Country**: 攻擊發生的國家。\n",
      "- **Sector**: 受攻擊的產業別。\n",
      "- **Number of Affected Users**: 受影響的使用者數量。\n",
      "- **Incident Resolution Time (in Hours)**: 事件解決所需時間（小時）。\n",
      "- **Financial Loss (in Million $)**: 財務損失（百萬美元），此為我們的**目標變數**。\n",
      "\n",
      "在 Streamlit 應用程式的「分析頁面」中，「資料概覽」和「特徵分析」分頁提供了對資料的深入探索。"
     ]
    },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Set Matplotlib font to avoid Chinese display issues (亂碼)\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS'] # Or any other font that supports Chinese characters\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 載入資料集\n",
    "df = pd.read_csv('Global_Cybersecurity_Threats_2015-2024.csv')\n",
    "\n",
    "print(\"### 資料集預覽 ###\")\n",
    "display(df.head())\n",
    "print(f\"\n### 資料集維度: {df.shape[0]} 行, {df.shape[1]} 列\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"### 資料集描述 ###\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"### 資料集資訊 ###\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"### 財務損失 (目標變數) 分佈 ###\")\n",
    "financial_loss = df['Financial Loss (in Million $)']\n",
    "\n",
    "# Calculate Skewness\n",
    "skewness = financial_loss.skew()\n",
    "print(f\"**偏度 (Skewness):** {skewness:.2f}\")\n",
    "if skewness > 0.5:\n",
    "    print(\"分佈呈右偏（正偏），表示有少數極大的損失值。\")\n",
    "elif skewness < -0.5:\n",
    "    print(\"分佈呈左偏（負偏）。\")\n",
    "else:\n",
    "    print(\"分佈大致對稱。\")\n",
    "\n",
    "# Plot distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.histplot(financial_loss, kde=False, ax=ax, stat=\"density\", label=\"Actual Distribution\")\n",
    "\n",
    "# Overlay normal distribution\n",
    "xmin, xmax = ax.get_xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, financial_loss.mean(), financial_loss.std())\n",
    "ax.plot(x, p, 'k', linewidth=2, label=\"Normal Distribution\")\n",
    "\n",
    "ax.set_title('Distribution of Financial Loss vs. Normal Distribution')\n",
    "ax.set_xlabel('Financial Loss (in Million $)')\n",
    "ax.set_ylabel('Density')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 資料準備 (Data Preparation)\n",
    "\n",
    "此階段由 `prepare_data.py` 腳本負責，主要執行以下步驟：\n",
    "\n",
    "1.  **載入資料**：從 CSV 檔案載入資料集。\n",
    "2.  **特徵工程**：\n",
    "    *   **獨熱編碼 (One-Hot Encoding)**：將所有類別特徵（如 `Attack Type`, `Country`）轉換為數值格式，以便機器學習模型能夠處理。\n",
    "3.  **資料標準化**：\n",
    "    *   使用 `StandardScaler` 對所有數值特徵進行標準化，使其具有零均值和單位變異數。這一步驟對於線性模型和 RFE 的穩定性至關重要。\n",
    "4.  **資料分割**：\n",
    "    *   將處理後的資料集以 80/20 的比例分割為訓練集和測試集。此過程中使用固定的 `random_state` 以確保結果的可重現性。\n",
    "5.  **儲存產物**：將處理好的訓練集/測試集（`.npy` 格式）、`StandardScaler` 物件、以及特徵名稱列表儲存為檔案，供後續模型訓練和應用程式使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "df = pd.read_csv('Global_Cybersecurity_Threats_2015-2024.csv')\n",
    "\n",
    "# 設定 target 與 features\n",
    "target = \"Financial Loss (in Million $)\"\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# 類別欄位轉換\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# 數值標準化\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 訓練/測試集切分\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Save the data and scaler\n",
    "np.save('X_train.npy', X_train)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('y_test.npy', y_test)\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "joblib.dump(X.columns, 'feature_names.pkl')\n",
    "\n",
    "# Save full processed X and y for statsmodels\n",
    "np.save('X_full_processed.npy', X)\n",
    "np.save('y_full_processed.npy', y)\n",
    "print('\n✅ 資料準備完成，相關檔案已儲存。')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型建立 (Modeling)\n",
    "\n",
    "此階段由 `train_model.py` 腳本負責。我們建立了兩個互補的迴歸模型：\n",
    "\n",
    "1.  **Scikit-learn 線性迴歸 + RFE**:\n",
    "    *   **遞歸特徵消除 (RFE)**：首先，我們使用 RFE 來自動篩選出對預測財務損失最重要的 10 個特徵。\n",
    "    *   **線性迴歸 (Linear Regression)**：接著，我們使用一個標準的線性迴歸模型，僅在 RFE 篩選出的特徵上進行訓練。這個模型 (`cyber_risk_model.pkl`) 主要用於產生最終的預測值。\n",
    "\n",
    "2.  **Statsmodels OLS 模型**:\n",
    "    *   我們另外使用 `statsmodels` 函式庫建立了一個普通最小二乘法 (OLS) 模型。此模型 (`statsmodels_model.pkl`) 的優勢在於提供詳細的統計摘要，包括特徵的 p-value、信賴區間等。\n",
    "    *   在本專案中，它主要用於計算預測值的 **95% 預測區間**，並在「特徵重要性」分析中提供係數參考。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "import joblib\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data for sklearn model\n",
    "X_train = np.load('X_train.npy', allow_pickle=True)\n",
    "y_train = np.load('y_train.npy', allow_pickle=True)\n",
    "\n",
    "# Create a Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Use Recursive Feature Elimination (RFE) to select the best features\n",
    "rfe = RFE(model, n_features_to_select=10)\n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "\n",
    "# Train the sklearn model on the selected features\n",
    "model.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Save the trained sklearn model and the RFE selector\n",
    "joblib.dump(model, 'cyber_risk_model.pkl')\n",
    "joblib.dump(rfe, 'rfe.joblib')\n",
    "\n",
    "print(\"Sklearn model trained and saved successfully.\")\n",
    "\n",
    "# --- Fit and Save Statsmodels OLS Model ---\n",
    "\n",
    "# Load full processed X and y for statsmodels\n",
    "X_full_processed = np.load('X_full_processed.npy', allow_pickle=True)\n",
    "y_full_processed = np.load('y_full_processed.npy', allow_pickle=True)\n",
    "feature_names = joblib.load('feature_names.pkl')\n",
    "\n",
    "# Create DataFrame for statsmodels and ensure numeric types\n",
    "X_sm = pd.DataFrame(X_full_processed, columns=feature_names).astype(float)\n",
    "y_sm = pd.Series(y_full_processed).astype(float)\n",
    "\n",
    "# Add a constant to the X for statsmodels (for intercept)\n",
    "X_sm = sm.add_constant(X_sm)\n",
    "\n",
    "# Get the names of the features selected by RFE\n",
    "selected_feature_names_rfe = feature_names[rfe.support_].tolist()\n",
    "if 'const' not in selected_feature_names_rfe:\n",
    "    selected_feature_names_rfe.insert(0, 'const')\n",
    "\n",
    "# Filter X_sm to include only the RFE-selected features\n",
    "X_sm_selected = X_sm[selected_feature_names_rfe]\n",
    "\n",
    "# Fit statsmodels OLS model\n",
    "sm_model = sm.OLS(y_sm, X_sm_selected).fit()\n",
    "\n",
    "# Save the statsmodels model\n",
    "joblib.dump(sm_model, 'statsmodels_model.pkl')\n",
    "\n",
    "print(\"Statsmodels OLS model trained and saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型評估 (Evaluation)\n",
    "\n",
    "模型的評估在 Streamlit 應用程式的「分析頁面」中進行，主要包含以下幾個部分：\n",
    "\n",
    "- **迴歸指標**：在「模型性能」區塊，我們計算並展示了三個關鍵的迴歸評估指標：\n",
    "  - **R-squared (R²)**: 解釋了模型對目標變數變異性的解釋程度。\n",
    "  - **Root Mean Squared Error (RMSE)**: 衡量預測值與實際值之間的平均誤差幅度。\n",
    "  - **Mean Absolute Error (MAE)**: 提供了另一種誤差的衡量方式，較不受異常值影響。\n",
    "\n",
    "- **視覺化評估**：\n",
    "  - **實際 vs. 預測圖**：一個散點圖，用於比較實際損失與模型預測損失的一致性。\n",
    "  - **殘差圖**：用於檢查誤差是否隨機分佈，是評估模型假設的重要工具。\n",
    "  - **混淆矩陣**：雖然這是迴歸問題，但我們將連續的損失值分為「高、中、低」三個等級，並建立了一個互動式的混淆矩陣。這讓使用者可以從「分類」的角度評估模型在不同損失等級上的預測準確度，並可依特定特徵進行篩選分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set Matplotlib font to avoid Chinese display issues (亂碼)\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS'] # Or any other font that supports Chinese characters\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# Load test data\n",
    "X_test = np.load('X_test.npy', allow_pickle=True)\n",
    "y_test = np.load('y_test.npy', allow_pickle=True)\n",
    "\n",
    "# Load model and rfe\n",
    "model = joblib.load('cyber_risk_model.pkl')\n",
    "rfe = joblib.load('rfe.joblib')\n",
    "sm_model = joblib.load('statsmodels_model.pkl')\n",
    "full_feature_names = joblib.load('feature_names.pkl')\n",
    "\n",
    "# Transform test data\n",
    "selected_X_test = rfe.transform(X_test)\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = model.predict(selected_X_test)\n",
    "\n",
    "st.subheader(\"### 模型評估指標 ###\")\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"- **R-squared (R²):** {r2:.3f}\")\n",
    "print(f\"- **Root Mean Squared Error (RMSE):** {rmse:.3f}\")\n",
    "print(f\"- **Mean Absolute Error (MAE):** {mae:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#### 實際 vs. 預測損失散點圖 ###\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=y_test, y=y_pred)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel(\"Actual Financial Loss (Million $)\")\n",
    "plt.ylabel(\"Predicted Financial Loss (Million $)\")\n",
    "plt.title(\"Actual vs. Predicted Financial Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#### 殘差圖 ###\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=y_pred, y=(y_test - y_pred))\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel(\"Predicted Financial Loss (Million $)\")\n",
    "plt.ylabel(\"Residuals (Actual - Predicted)\")\n",
    "plt.title(\"Residuals Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔍 RFE 特徵分析 (遞歸特徵消除)\n",
    "RFE 透過遞歸地考慮越來越小的特徵集來選擇特徵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RFE 模型選擇了 {rfe.n_features_} 個特徵。\")\n",
    "selected_rfe_features = full_feature_names[rfe.support_]\n",
    "print(\"#### RFE 選擇的特徵:\")\n",
    "for feature in selected_rfe_features.tolist():\n",
    "    print(f\"- `{feature}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🌟 特徵重要性\n",
    "對於線性模型，特徵重要性可以從係數的絕對大小推斷出來。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_model_coefs = sm_model.params.drop('const', errors='ignore')\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': sm_model_coefs.index,\n",
    "    'Coefficient': sm_model_coefs.values\n",
    "})\n",
    "feature_importance_df['Absolute_Coefficient'] = feature_importance_df['Coefficient'].abs()\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Absolute_Coefficient', ascending=False)\n",
    "\n",
    "print(\"#### 特徵係數 (來自 Statsmodels OLS 模型):\")\n",
    "display(feature_importance_df[['Feature', 'Coefficient']].head(15))\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.barplot(x='Absolute_Coefficient', y='Feature', data=feature_importance_df.head(15), palette='viridis')\n",
    "plt.title('Top 15 Feature Importances (Absolute Coefficients)')\n",
    "plt.xlabel('Absolute Coefficient Value')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📊 異常值分析\n",
    "識別並視覺化數值特徵和財務損失中的潛在異常值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original data to get original numerical columns\n",
    "df_analysis = pd.read_csv('Global_Cybersecurity_Threats_2015-2024.csv')\n",
    "original_numerical_cols = ['Year', 'Number of Affected Users', 'Incident Resolution Time (in Hours)']\n",
    "\n",
    "print(\"#### 數值特徵的盒鬚圖 (異常值檢測) ###\")\n",
    "for col in original_numerical_cols + ['Financial Loss (in Million $)']:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.boxplot(x=df_analysis[col])\n",
    "    plt.title(f'Box Plot of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.show()\n",
    "\n",
    "print(\"#### 財務損失異常值檢測 (使用 IQR) ###\")\n",
    "Q1 = df_analysis['Financial Loss (in Million $)'].quantile(0.25)\n",
    "Q3 = df_analysis['Financial Loss (in Million $)'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outlier_threshold_upper = Q3 + 1.5 * IQR\n",
    "outlier_threshold_lower = Q1 - 1.5 * IQR\n",
    "\n",
    "df_outliers = df_analysis[(df_analysis['Financial Loss (in Million $)'] > outlier_threshold_upper) |\n",
    "                          (df_analysis['Financial Loss (in Million $)'] < outlier_threshold_lower)]\n",
    "\n",
    "if not df_outliers.empty:\n",
    "    print(f\"使用 IQR 方法在財務損失中發現 {len(df_outliers)} 個潛在異常值。\")\n",
    "    display(df_outliers[['Year', 'Financial Loss (in Million $)', 'Attack Type', 'Country']])\n",
    "else:\n",
    "    print(\"使用 IQR 方法在財務損失中未發現顯著異常值。\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=df_analysis['Year'], y=df_analysis['Financial Loss (in Million $)'], label='All Data')\n",
    "if not df_outliers.empty:\n",
    "    sns.scatterplot(x=df_outliers['Year'], y=df_outliers['Financial Loss (in Million $)'], color='red', label='Outlier')\n",
    "plt.axhline(y=outlier_threshold_upper, color='orange', linestyle=':', label='Upper IQR Bound')\n",
    "plt.axhline(y=outlier_threshold_lower, color='orange', linestyle=':', label='Lower IQR Bound')\n",
    "plt.title('Financial Loss vs. Year with Outlier Bounds')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Financial Loss (Million $)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📈 混淆矩陣\n",
    "為了產生混淆矩陣，我們將連續的財務損失目標變數轉換為三個類別：低、中、高。您可以依特定特徵篩選資料，觀察模型在不同情境下的表現。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original data to get original categorical columns\n",
    "df_analysis = pd.read_csv('Global_Cybersecurity_Threats_2015-2024.csv')\n",
    "original_categorical_columns_map = {}\n",
    "for feature in joblib.load('feature_names.pkl'):\n",
    "    if feature not in ['Year', 'Number of Affected Users', 'Incident Resolution Time (in Hours)', 'Financial Loss (in Million $)']:\n",
    "        parts = feature.split('_', 1)\n",
    "        if len(parts) > 1:\n",
    "            category = parts[0]\n",
    "            option = parts[1]\n",
    "            if category not in original_categorical_columns_map:\n",
    "                original_categorical_columns_map[category] = []\n",
    "            original_categorical_columns_map[category].append(option)\n",
    "\n",
    "# Recreate the train-test split on the original data to get access to original features for filtering\n",
    "target = \"Financial Loss (in Million $)\"\n",
    "features = df_analysis.drop(columns=[target])\n",
    "y_full = df_analysis[target]\n",
    "_, X_test_original_df, _, y_test = train_test_split(features, y_full, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load the processed test set to make predictions\n",
    "X_test_processed = np.load('X_test.npy', allow_pickle=True)\n",
    "selected_X_test = rfe.transform(X_test_processed)\n",
    "y_pred = model.predict(selected_X_test)\n",
    "\n",
    "# --- Confusion Matrix Calculation and Display ---\n",
    "# Define bins and labels for categorization based on the filtered data\n",
    "try:\n",
    "    bins = pd.qcut(y_test, q=3, retbins=True, duplicates='drop')[1]\n",
    "    labels = [\"低\", \"中\", \"高\"]\n",
    "except ValueError: # Happens if not enough unique values for 3 quantiles\n",
    "    try:\n",
    "        bins = pd.qcut(y_test, q=2, retbins=True, duplicates='drop')[1]\n",
    "        labels = [\"低\", \"高\"]\n",
    "    except ValueError: # Happens if all values are the same\n",
    "        bins = [y_test.min(), y_test.max()]\n",
    "        labels = [\"單一值\"]\n",
    "\n",
    "y_test_cat = pd.cut(y_test, bins=bins, labels=labels, include_lowest=True)\n",
    "y_pred_cat = pd.cut(y_pred, bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Handle cases where predictions might fall out of y_test bins\n",
    "if y_pred_cat.isnull().any():\n",
    "    y_pred_cat = y_pred_cat.cat.add_categories(['預測超出範圍'])\n",
    "    y_pred_cat = y_pred_cat.fillna('預測超出範圍')\n",
    "    all_labels = list(labels) + ['預測超出範圍']\n",
    "else:\n",
    "    all_labels = labels\n",
    "\n",
    "print(\"#### 損失類別定義: ###\")\n",
    "if len(bins) > 1 and \"單一值\" not in labels:\n",
    "    for i in range(len(bins) - 1):\n",
    "        print(f\"- **{labels[i]}**: ${bins[i]:.2f}M - ${bins[i+1]:.2f}M\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test_cat, y_pred_cat, labels=all_labels)\n",
    "cm_df = pd.DataFrame(cm, index=all_labels, columns=all_labels)\n",
    "\n",
    "print(\"#### 混淆矩陣: ###\")\n",
    "print(\"此矩陣顯示了模型在預測不同損失等級時的表現。\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix for Financial Loss Categories')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 部署 (Deployment)\n",
    "\n",
    "本專案的最終產出是一個部署在 Streamlit 上的互動式網頁應用程式 (`5114050013_hw2.py`)。\n",
    "\n",
    "**應用程式功能：**\n",
    "\n",
    "- **預測頁面**：使用者可以在側邊欄輸入各種攻擊事件的參數（如年份、攻擊類型、影響用戶數等），點擊按鈕後，應用程式會立即回傳預測的財務損失金額，並以圖表形式展示其 95% 的預測區間。\n",
    "\n",
    "- **分析頁面**：提供了一個功能豐富的儀表板，讓使用者可以：\n",
    "  - 概覽資料集的統計特性與分佈。\n",
    "  - 探索不同特徵之間的關係以及它們對財務損失的影響。\n",
    "  - 查看模型的詳細性能指標與評估圖表。\n",
    "  - 分析 RFE 所選出的重要特徵。\n",
    "  - 透過互動式混淆矩陣，深入了解模型在特定情境下的分類表現。"
   ]
  },
    {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如何部署到 Streamlit Cloud\n",
    "1. Push 專案資料夾 to GitHub\n",
    "2. 至 https://share.streamlit.io ，點擊 “Create app”\n",
    "3. Repository：下拉選擇 candice-wu/Cybersecurity_HW_02_Multiple_Linear_Regression\n",
    "4. Branch：Main\n",
    "5. Main file path：5114050013_hw2.py\n",
    "6. App URL (optional)：預設可以維持，或改掉並另外命名 ，如：https://hw02-multiple-linear-regression\n",
    "7. 點擊 “Deploy” 即完成部署\n",
    "\n",
    "## 如何執行專案\n",
    "\n",
    "1.  **安裝依賴函式庫**:\n",
    "    ```bash\n",
    "    pip install -r requirements.txt\n",
    "    ```\n",
    "\n",
    "2.  **準備資料與訓練模型**:\n",
    "    執行以下腳本來準備資料並訓練模型。\n",
    "    ```bash\n",
    "    python prepare_data.py\n",
    "    python train_model.py\n",
    "    ```\n",
    "\n",
    "3.  **啟動應用程式**:\n",
    "    ```bash\n",
    "    streamlit run 5114050013_hw2.py\n",
    "    ```\n",
    "    接著在瀏覽器中開啟顯示的 URL。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
